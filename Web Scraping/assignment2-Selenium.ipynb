{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49331c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all required libraries\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import time \n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4833d7",
   "metadata": {},
   "source": [
    "<b>Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10\n",
    "jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52fb0ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to web driver\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "url=(\"https://www.naukri.com/\")\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea269402",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding web element for search job and location bar using relative xpath\n",
    "search_job=driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[1]/div/div/div/input')\n",
    "search_locn=driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[3]/div/div/div/input\")\n",
    "search_job.send_keys(\"Data Analyst\")\n",
    "search_locn.send_keys(\"Bangalore\")\n",
    "\n",
    "#clicking using absolute xapth function \n",
    "search_btn=driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[6]\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8a8ad72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hiring For Business Data Analyst - Bangalore</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Synechron</td>\n",
       "      <td>5-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Junior Data Analyst/ Scientist- Fresher Position</td>\n",
       "      <td>Kolkata, Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Sejal Consulting Hub</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Assistant Clinical Data Analyst</td>\n",
       "      <td>(WFH during Covid)</td>\n",
       "      <td>Labcorp Drug Development India Private Limited</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Analyst - CRM</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Gojek Tech</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lead - Data Analyst / Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Axim Technologies</td>\n",
       "      <td>12-14 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hiring For Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>SMEDC SERVICES PRIVATE LIMITED</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Analyst - CRM</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>GO-JEK India</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>(WFH during Covid)</td>\n",
       "      <td>Verizon</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          job_title  \\\n",
       "0      Hiring For Business Data Analyst - Bangalore   \n",
       "1  Junior Data Analyst/ Scientist- Fresher Position   \n",
       "2                   Assistant Clinical Data Analyst   \n",
       "3                         Senior Data Analyst - CRM   \n",
       "4                   Lead - Data Analyst / Scientist   \n",
       "5                           Hiring For Data Analyst   \n",
       "6                               Senior Data Analyst   \n",
       "7                               Senior Data Analyst   \n",
       "8                         Senior Data Analyst - CRM   \n",
       "9                                      Data Analyst   \n",
       "\n",
       "                                     job_location  \\\n",
       "0                             Bangalore/Bengaluru   \n",
       "1  Kolkata, Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "2                              (WFH during Covid)   \n",
       "3                             Bangalore/Bengaluru   \n",
       "4                             Bangalore/Bengaluru   \n",
       "5                             Bangalore/Bengaluru   \n",
       "6                             Bangalore/Bengaluru   \n",
       "7                             Bangalore/Bengaluru   \n",
       "8                             Bangalore/Bengaluru   \n",
       "9                              (WFH during Covid)   \n",
       "\n",
       "                                     company_name experience_required  \n",
       "0                                       Synechron             5-7 Yrs  \n",
       "1                            Sejal Consulting Hub             0-3 Yrs  \n",
       "2  Labcorp Drug Development India Private Limited             0-2 Yrs  \n",
       "3                                      Gojek Tech             2-5 Yrs  \n",
       "4                               Axim Technologies           12-14 Yrs  \n",
       "5                                        Flipkart             4-8 Yrs  \n",
       "6                                         Walmart             4-7 Yrs  \n",
       "7                  SMEDC SERVICES PRIVATE LIMITED             4-8 Yrs  \n",
       "8                                    GO-JEK India             4-8 Yrs  \n",
       "9                                         Verizon             4-9 Yrs  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating empty list for scraping data\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n",
    "\n",
    "#scraping the job_title\n",
    "title_tag=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tag:\n",
    "    job_title.append(i.text)\n",
    "    \n",
    "#scraping job_location\n",
    "locn_tag=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]/span')\n",
    "for i in locn_tag:\n",
    "    job_location.append(i.text)\n",
    "    \n",
    "#scraping company_name\n",
    "company_tag=driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tag:\n",
    "    company_name.append(i.text)\n",
    "    \n",
    "#scraping experince_required\n",
    "exp_tag=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]/span')\n",
    "for i in exp_tag:\n",
    "    experience_required.append(i.text)\n",
    "    \n",
    "# creating the dataframe from the scraped data and taking only first 10 jobs\n",
    "df=pd.DataFrame({})\n",
    "df[\"job_title\"]=job_title[0:10]\n",
    "df['job_location']=job_location[0:10]\n",
    "df['company_name']=company_name[0:10]\n",
    "df['experience_required']=experience_required[0:10]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2fec2c",
   "metadata": {},
   "source": [
    "<b>Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e6c6fb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to web driver\n",
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "url=(\"https://www.naukri.com/\")\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2749d41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding web element for search job and location bar using relative xpath\n",
    "search_job=driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[1]/div/div/div/input\")\n",
    "search_job.send_keys(\"Data Scientist\")\n",
    "search_locn=driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[3]/div/div/div/input\")\n",
    "search_locn.send_keys(\"Bangalore\")\n",
    "\n",
    "#clicking using absolute xapth function \n",
    "search_btn=driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[6]\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2a2c80ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>company_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Siemens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Manager - Lead Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>ExecBoardinAsia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>Shell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Junior Programmer - Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>GSK India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lead/Senior Data Scientist (NLP)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Samya.AI A FRACTAL Entity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sr . Data Scientist</td>\n",
       "      <td>(WFH during Covid)</td>\n",
       "      <td>RKSV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sr. Data Scientist</td>\n",
       "      <td>Mumbai, Bangalore/Bengaluru</td>\n",
       "      <td>NutaNXT Technologies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Scientist, Data Sciences</td>\n",
       "      <td>Pune, Bangalore/Bengaluru, Mumbai (All Areas)</td>\n",
       "      <td>Vmware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>(WFH during Covid)</td>\n",
       "      <td>Gadgeon Smart Systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Dell</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              job_title  \\\n",
       "0                     Sr Data Scientist   \n",
       "1  Senior Manager - Lead Data Scientist   \n",
       "2              Associate Data Scientist   \n",
       "3    Junior Programmer - Data Scientist   \n",
       "4      Lead/Senior Data Scientist (NLP)   \n",
       "5                   Sr . Data Scientist   \n",
       "6                    Sr. Data Scientist   \n",
       "7  Senior Data Scientist, Data Sciences   \n",
       "8                   Lead Data Scientist   \n",
       "9                 Senior Data Scientist   \n",
       "\n",
       "                                    job_location               company_name  \n",
       "0                            Bangalore/Bengaluru                    Siemens  \n",
       "1                            Bangalore/Bengaluru            ExecBoardinAsia  \n",
       "2                   Chennai, Bangalore/Bengaluru                      Shell  \n",
       "3                            Bangalore/Bengaluru                  GSK India  \n",
       "4                            Bangalore/Bengaluru  Samya.AI A FRACTAL Entity  \n",
       "5                             (WFH during Covid)                       RKSV  \n",
       "6                    Mumbai, Bangalore/Bengaluru       NutaNXT Technologies  \n",
       "7  Pune, Bangalore/Bengaluru, Mumbai (All Areas)                     Vmware  \n",
       "8                             (WFH during Covid)      Gadgeon Smart Systems  \n",
       "9                            Bangalore/Bengaluru                       Dell  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating empty list for scraping data\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "\n",
    "#scraping the job_title\n",
    "title_tag=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tag:\n",
    "    job_title.append(i.text)\n",
    "\n",
    "#scraping job_location    \n",
    "locn_tag=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]/span')\n",
    "for i in locn_tag:\n",
    "    job_location.append(i.text)\n",
    "    \n",
    "#scraping company_name\n",
    "company_tag=driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]') \n",
    "for i in company_tag:\n",
    "    company_name.append(i.text)\n",
    "    \n",
    "    \n",
    "df=pd.DataFrame({})\n",
    "df[\"job_title\"]=job_title[0:10]\n",
    "df['job_location']=job_location[0:10]\n",
    "df['company_name']=company_name[0:10]    \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942ca78c",
   "metadata": {},
   "source": [
    "<b>Q3: In this question you have to scrape data using the filters available on the webpage as shown below:<br>You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scraped data.</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fa8e4f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to web driver \n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "url=(\"https://www.naukri.com/\")\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1445b1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding web element for search job and location bar using relative xpath\n",
    "search_job=driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[1]/div/div/div/input\")\n",
    "search_job.send_keys(\"Data Scientist\")\n",
    "\n",
    "#clicking using absolute xapth \n",
    "search_btn=driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[6]\")\n",
    "search_btn.click()\n",
    "\n",
    "#clicking filters by selecting check boxes using absolute xpath\n",
    "loc=driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[3]/div[2]/div[3]/label/i\")\n",
    "loc.click()\n",
    "salary=driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[4]/div[2]/div[2]/label/i\")\n",
    "salary.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d52c4b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Job Opportunity || Data Scientist || HCL Techn...</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "      <td>HCL</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist | Python | Machine Learning | D...</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>Schlesinger Group</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Scientist I</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Delhivery</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>T &amp; A Solutions</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Openings For Jr/mid/Sr level data Scientists</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...</td>\n",
       "      <td>Pluto seven business solutions (p) limited</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist role</td>\n",
       "      <td>(WFH during Covid)</td>\n",
       "      <td>Mount Talent Consulting Private Limited</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Urgent Hiring For Data Scientist</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Pune, Gurgaon/G...</td>\n",
       "      <td>Mount Talent Consulting Private Limited</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Urgent Hiring For Data Scientist</td>\n",
       "      <td>(WFH during Covid)</td>\n",
       "      <td>Mount Talent Consulting Private Limited</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist role</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Mount Talent Consulting Private Limited</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist role</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Mount Talent Consulting Private Limited</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0  Job Opportunity || Data Scientist || HCL Techn...   \n",
       "1  Data Scientist | Python | Machine Learning | D...   \n",
       "2                            Senior Data Scientist I   \n",
       "3                                     Data Scientist   \n",
       "4       Openings For Jr/mid/Sr level data Scientists   \n",
       "5                                Data Scientist role   \n",
       "6                   Urgent Hiring For Data Scientist   \n",
       "7                   Urgent Hiring For Data Scientist   \n",
       "8                                Data Scientist role   \n",
       "9                                Data Scientist role   \n",
       "\n",
       "                                        job_location  \\\n",
       "0                                        Delhi / NCR   \n",
       "1               Noida, Gurgaon/Gurugram, Delhi / NCR   \n",
       "2                                   Gurgaon/Gurugram   \n",
       "3                                   Gurgaon/Gurugram   \n",
       "4  Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...   \n",
       "5                                 (WFH during Covid)   \n",
       "6  Noida, Hyderabad/Secunderabad, Pune, Gurgaon/G...   \n",
       "7                                 (WFH during Covid)   \n",
       "8              Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "9              Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "\n",
       "                                 company_name experience_required  \n",
       "0                                         HCL             2-6 Yrs  \n",
       "1                           Schlesinger Group             0-3 Yrs  \n",
       "2                                   Delhivery             3-7 Yrs  \n",
       "3                             T & A Solutions             2-6 Yrs  \n",
       "4  Pluto seven business solutions (p) limited             2-6 Yrs  \n",
       "5     Mount Talent Consulting Private Limited             1-4 Yrs  \n",
       "6     Mount Talent Consulting Private Limited             1-6 Yrs  \n",
       "7     Mount Talent Consulting Private Limited             1-6 Yrs  \n",
       "8     Mount Talent Consulting Private Limited             1-3 Yrs  \n",
       "9     Mount Talent Consulting Private Limited             1-3 Yrs  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating empty list for scraping data\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n",
    "\n",
    "#scraping job title\n",
    "job_tag=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in job_tag:\n",
    "    job_title.append(i.text)\n",
    "\n",
    "#scraping job_location\n",
    "locn_tag=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]/span')\n",
    "for i in locn_tag:\n",
    "    job_location.append(i.text)\n",
    "\n",
    "#scraping company_name    \n",
    "company_tag=driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tag:\n",
    "    company_name.append(i.text)\n",
    "\n",
    "#scraping experience_required    \n",
    "exp_tag=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]/span')\n",
    "for i in exp_tag:\n",
    "    experience_required.append(i.text)\n",
    "    \n",
    "    \n",
    "# creating the dataframe from the scraped data and taking only first 10 jobs\n",
    "df=pd.DataFrame({})\n",
    "df[\"job_title\"]=job_title[0:10]\n",
    "df['job_location']=job_location[0:10]\n",
    "df['company_name']=company_name[0:10]\n",
    "df['experience_required']=experience_required[0:10]\n",
    "df    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d2203f",
   "metadata": {},
   "source": [
    "<b>Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "The attributes which you have to scrape is ticked marked in the below image<br>To scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands andmore” is written and\n",
    "click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this pageyou can scrap the\n",
    "required data as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "78b6bc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(3)\n",
    "url = \"https://www.flipkart.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9a850dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(2)\n",
    "#locating the search bar\n",
    "search_bar=driver.find_element_by_class_name(\"_3704LK\")\n",
    "search_bar.send_keys('sunglasses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6dfc6d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)\n",
    "#locating the button and clicking it toh search for sunglasses\n",
    "button=driver.find_element_by_class_name('L0Z3Pu')\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1a8a2927",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching brands of sunglasses\n",
    "brand=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "brand_names=[]\n",
    "for i in brand:\n",
    "    brand_names.append(i.text)\n",
    "    \n",
    "#fetching product description of sunglasses\n",
    "product_desc=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "product_description=[]\n",
    "for i in product_desc:\n",
    "    product_description.append(i.text)  \n",
    "    \n",
    "#fetching price of sunglasses\n",
    "price=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "price_of_sunglass=[]\n",
    "for i in price:\n",
    "    price_of_sunglass.append(i.text)  \n",
    "    \n",
    "#fetching discount% of sunglasses\n",
    "discount=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\")\n",
    "discount_percentage=[]\n",
    "for i in discount:\n",
    "    discount_percentage.append(i.text)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "77fa85f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching and clicking next button\n",
    "next_button=driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]')\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "63125cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching brands of sunglasses\n",
    "brand1=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "brand_names1=[]\n",
    "for i in brand1:\n",
    "    brand_names1.append(i.text)\n",
    "    \n",
    "#fetching product description of sunglasses\n",
    "product_desc1=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "product_description1=[]\n",
    "for i in product_desc1:\n",
    "    product_description1.append(i.text)\n",
    "    \n",
    "#fetching price of sunglasses\n",
    "price1=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "price_of_sunglass1=[]\n",
    "for i in price1:\n",
    "    price_of_sunglass1.append(i.text)\n",
    "    \n",
    "#fetching discount% of sunglasses\n",
    "discount1=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\")\n",
    "discount_percentage1=[]\n",
    "for i in discount1:\n",
    "    discount_percentage1.append(i.text)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9b2e86d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching and clicking next button\n",
    "next_button=driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]')\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "cae5f258",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching brands of sunglasses\n",
    "brand2=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "brand_names2=[]\n",
    "for i in brand2:\n",
    "    brand_names2.append(i.text)\n",
    "    \n",
    "#fetching product description of sunglasses\n",
    "product_desc2=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "product_description2=[]\n",
    "for i in product_desc2:\n",
    "    product_description2.append(i.text)\n",
    "    \n",
    "#fetching price of sunglasses\n",
    "price2=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "price_of_sunglass2=[]\n",
    "for i in price2:\n",
    "    price_of_sunglass2.append(i.text)\n",
    "    \n",
    "#fetching discount% of sunglasses\n",
    "discount2=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\")\n",
    "discount_percentage2=[]\n",
    "for i in discount2:\n",
    "    discount_percentage2.append(i.text)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9b5aff60",
   "metadata": {},
   "outputs": [],
   "source": [
    "brands_list=brand_names+brand_names1+brand_names2\n",
    "product_descriptions=product_description+product_description1+product_description2\n",
    "prices=price_of_sunglass+price_of_sunglass1+price_of_sunglass2\n",
    "discounts=discount_percentage+discount_percentage1+discount_percentage2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ee7010ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart UV Protection Aviator Sunglasses (...</td>\n",
       "      <td>₹999</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Retro Square Sunglasse...</td>\n",
       "      <td>₹349</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>₹200</td>\n",
       "      <td>87% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹248</td>\n",
       "      <td>90% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹759</td>\n",
       "      <td>15% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (Free Size)</td>\n",
       "      <td>₹426</td>\n",
       "      <td>78% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>PHENOMENAL</td>\n",
       "      <td>UV Protection, Gradient Rectangular Sunglasses...</td>\n",
       "      <td>₹309</td>\n",
       "      <td>84% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>Mirrored Aviator Sunglasses (55)</td>\n",
       "      <td>₹383</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Polarized, UV Protection Sports Sunglasses (Fr...</td>\n",
       "      <td>₹359</td>\n",
       "      <td>76% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>SKYZA INDIA</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (Free Size)</td>\n",
       "      <td>₹495</td>\n",
       "      <td>72% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             brand                                        description price  \\\n",
       "0    VINCENT CHASE  by Lenskart UV Protection Aviator Sunglasses (...  ₹999   \n",
       "1   ROZZETTA CRAFT  UV Protection, Gradient Retro Square Sunglasse...  ₹349   \n",
       "2           PIRASO              UV Protection Aviator Sunglasses (54)  ₹200   \n",
       "3        Elligator                UV Protection Round Sunglasses (54)  ₹248   \n",
       "4         Fastrack      UV Protection Wayfarer Sunglasses (Free Size)  ₹759   \n",
       "..             ...                                                ...   ...   \n",
       "95  ROZZETTA CRAFT  UV Protection Retro Square Sunglasses (Free Size)  ₹426   \n",
       "96      PHENOMENAL  UV Protection, Gradient Rectangular Sunglasses...  ₹309   \n",
       "97  ROZZETTA CRAFT                   Mirrored Aviator Sunglasses (55)  ₹383   \n",
       "98       ROYAL SON  Polarized, UV Protection Sports Sunglasses (Fr...  ₹359   \n",
       "99     SKYZA INDIA  UV Protection Retro Square Sunglasses (Free Size)  ₹495   \n",
       "\n",
       "   discount  \n",
       "0   50% off  \n",
       "1   82% off  \n",
       "2   87% off  \n",
       "3   90% off  \n",
       "4   15% off  \n",
       "..      ...  \n",
       "95  78% off  \n",
       "96  84% off  \n",
       "97  80% off  \n",
       "98  76% off  \n",
       "99  72% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sunglasses=pd.DataFrame({})\n",
    "sunglasses['brand']= brands_list[:100]\n",
    "sunglasses['description']= product_descriptions[:100]\n",
    "sunglasses['price']= prices[:100]\n",
    "sunglasses['discount']= discounts[:100]\n",
    "\n",
    "sunglasses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a3e5a6",
   "metadata": {},
   "source": [
    "<b>Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link:\n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb-includes- earpods-poweradapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC\n",
    "TSVZAXUHGREPBFGI&marketplace.\n",
    "When you will open the above link you will reach to the below shown webpage .<br>As shown in the above page you have to scrape the tick marked attributes.These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100 reviews</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8113927d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to the web driver\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(3)\n",
    "\n",
    "# Opening the website link\n",
    "url = \"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af9c1e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty list\n",
    "urls=[]\n",
    "review=[]\n",
    "full_review=[]\n",
    "stars=[]\n",
    "time.sleep(2)\n",
    "\n",
    "#scraping 10 pages of url\n",
    "url_1 = driver.find_elements_by_xpath(\"//a[@class='ge-49M _2Kfbh8']\")\n",
    "for i in url_1:\n",
    "    urls.append(i.get_attribute('href'))\n",
    "url_2 = driver.find_elements_by_xpath(\"//a[@class='ge-49M']\")\n",
    "for i in url_2:\n",
    "    urls.append(i.get_attribute('href'))\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    #scrapping the number of stars\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='col _2wzgFH K0kLPL']/div[1]/div[1]\"):\n",
    "        stars.append(j.text)\n",
    "    #scrapping the short review\n",
    "    for k in driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\"):\n",
    "        review.append(k.text)\n",
    "    #for scrapping the complete review\n",
    "    for l in driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']/div/div\"):\n",
    "        full_review.append(l.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "705351b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>full_review</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Just wow!</td>\n",
       "      <td>The ultimate performance\\nCamera is superb\\nTh...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>I use a Note10+ and have been using both iOS a...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Awesome</td>\n",
       "      <td>The phone is completely good\\nAs far as camera...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Decent product</td>\n",
       "      <td>Everything u ll like it when u use this iPhone...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Wonderful</td>\n",
       "      <td>Nice value for money good and best price I pho...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 review                                        full_review  \\\n",
       "0             Brilliant  The Best Phone for the Money\\n\\nThe iPhone 11 ...   \n",
       "1        Simply awesome  Really satisfied with the Product I received.....   \n",
       "2      Perfect product!  Amazing phone with great cameras and better ba...   \n",
       "3   Best in the market!  Great iPhone very snappy experience as apple k...   \n",
       "4     Worth every penny  Previously I was using one plus 3t it was a gr...   \n",
       "..                  ...                                                ...   \n",
       "95            Just wow!  The ultimate performance\\nCamera is superb\\nTh...   \n",
       "96    Terrific purchase  I use a Note10+ and have been using both iOS a...   \n",
       "97              Awesome  The phone is completely good\\nAs far as camera...   \n",
       "98       Decent product  Everything u ll like it when u use this iPhone...   \n",
       "99            Wonderful  Nice value for money good and best price I pho...   \n",
       "\n",
       "   stars  \n",
       "0      5  \n",
       "1      5  \n",
       "2      5  \n",
       "3      5  \n",
       "4      5  \n",
       "..   ...  \n",
       "95     5  \n",
       "96     5  \n",
       "97     5  \n",
       "98     3  \n",
       "99     5  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe\n",
    "iphone = pd.DataFrame({})\n",
    "iphone['review']= review\n",
    "iphone['full_review']= full_review\n",
    "iphone['stars']= stars\n",
    "\n",
    "iphone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f929eeb8",
   "metadata": {},
   "source": [
    "<b>Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com andsearch for “sneakers” in the\n",
    "search field.\n",
    "You have to scrape 4 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "As shown in the below image, you have to scrape the tick marked attributes.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "38bb6760",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to the webdriver\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "url = \"https://www.flipkart.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "b27fbee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#close log_in window\n",
    "log_in_pop_up = driver.find_element_by_xpath(\"//button[@class='_2KpZ6l _2doB4z']\")\n",
    "log_in_pop_up.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "a456fc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating the search bar\n",
    "search_bar=driver.find_element_by_class_name(\"_3704LK\")\n",
    "search_bar.clear()\n",
    "search_bar.send_keys('sneakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "a9b69341",
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating the button and clicking it to search for sneakers\n",
    "button=driver.find_element_by_class_name('L0Z3Pu')\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "03b1f025",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the empty list\n",
    "brand=[]\n",
    "description=[]\n",
    "price=[]\n",
    "discount=[]\n",
    "\n",
    "#scrapping the required details\n",
    "start=0\n",
    "end=4\n",
    "for page in range(start,end):#for loop for scrapping 4 page\n",
    "    brands=driver.find_elements_by_class_name('_2WkVRV')#scraping brands name by class name='_2WkVRV'\n",
    "    for i in brands:\n",
    "        brand.append(i.text)#appending the text in Brand list\n",
    "    prices=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")# scraping the price from the xpath\n",
    "    for i in prices:\n",
    "        price.append(i.text)\n",
    "    disc=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']//span\")# scraping the discount from the xpath\n",
    "    for i in disc:\n",
    "        discount.append(i.text)\n",
    "    nxt_button=driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")#scraping the list of buttons from the page\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href'))#getting the link from the list for next page\n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "628dfed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since in some records not getting description so try from inside of urls\n",
    "urls = []\n",
    "\n",
    "for page in range(0,4):#for loop for scrapping 4 page\n",
    "    \n",
    "    product_url = driver.find_elements_by_xpath(\"//a[@class='_2UzuFa']\")\n",
    "    for i in product_url:\n",
    "        urls.append(i.get_attribute('href'))\n",
    "    \n",
    "    nxt_button=driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")#scraping the list of buttons from the page\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href'))#getting the link from the list for next page\n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "84b1a91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    desc=driver.find_elements_by_xpath('//span[@class=\"B_NuCI\"]')#scraping description from the xpath\n",
    "    for i in desc:\n",
    "        description.append(i.text)#appending the description in list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "2730881e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PEHANOSA</td>\n",
       "      <td>Lightweight Pack Of 1 Trendy Sneakers Sneakers...</td>\n",
       "      <td>₹449</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zixer</td>\n",
       "      <td>White casual, gym,training &amp; canvas shoes for ...</td>\n",
       "      <td>₹631</td>\n",
       "      <td>68% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>luxury fashion</td>\n",
       "      <td>Sneakers For Men  (Navy)</td>\n",
       "      <td>₹449</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Magnolia</td>\n",
       "      <td>Casuals Walking Shoes Boxing &amp; Wrestling Shoes...</td>\n",
       "      <td>₹398</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>URBANBOX</td>\n",
       "      <td>Sneakers For Men  (Black, Red)</td>\n",
       "      <td>₹220</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Sneakers For Men  (White)</td>\n",
       "      <td>₹5,399</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Zsyto</td>\n",
       "      <td>Cozy Stylish And Fashion Printed Double Lace-U...</td>\n",
       "      <td>₹428</td>\n",
       "      <td>64% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>WHITE WALKERS</td>\n",
       "      <td>Combo Pack of 2 Casual Shoes Sneakers For Men ...</td>\n",
       "      <td>₹599</td>\n",
       "      <td>40% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Sneakers Sneakers For Men  (Grey)</td>\n",
       "      <td>₹892</td>\n",
       "      <td>34% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Alvery</td>\n",
       "      <td>Powerjet-05 casual shoes for men | Latest Styl...</td>\n",
       "      <td>₹599</td>\n",
       "      <td>33% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                        Description   Price  \\\n",
       "0         PEHANOSA  Lightweight Pack Of 1 Trendy Sneakers Sneakers...    ₹449   \n",
       "1            Zixer  White casual, gym,training & canvas shoes for ...    ₹631   \n",
       "2   luxury fashion                           Sneakers For Men  (Navy)    ₹449   \n",
       "3         Magnolia  Casuals Walking Shoes Boxing & Wrestling Shoes...    ₹398   \n",
       "4         URBANBOX                     Sneakers For Men  (Black, Red)    ₹220   \n",
       "..             ...                                                ...     ...   \n",
       "95            PUMA                          Sneakers For Men  (White)  ₹5,399   \n",
       "96           Zsyto  Cozy Stylish And Fashion Printed Double Lace-U...    ₹428   \n",
       "97   WHITE WALKERS  Combo Pack of 2 Casual Shoes Sneakers For Men ...    ₹599   \n",
       "98           BIRDE                  Sneakers Sneakers For Men  (Grey)    ₹892   \n",
       "99          Alvery  Powerjet-05 casual shoes for men | Latest Styl...    ₹599   \n",
       "\n",
       "   Discount  \n",
       "0   55% off  \n",
       "1   68% off  \n",
       "2   65% off  \n",
       "3   60% off  \n",
       "4   77% off  \n",
       "..      ...  \n",
       "95  50% off  \n",
       "96  64% off  \n",
       "97  40% off  \n",
       "98  34% off  \n",
       "99  33% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Brand':brand[:100],\n",
    "                'Description':description[:100],\n",
    "                'Price':price[:100],\n",
    "                'Discount':discount[:100]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8110f73",
   "metadata": {},
   "source": [
    "<b>Q7: Go to the link - https://www.myntra.com/shoes<br>\n",
    "Set Price filter to “Rs. 7149 to Rs. 14099 ” , Color filter to “Black”, as shown in the below image.<br>\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe\n",
    "description, price of the shoe as shown in the below image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "7e5d66e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to the web driver\n",
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "url=('https://www.myntra.com/shoes')\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "2f5ec4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on price filter\n",
    "filter_price=driver.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/div')\n",
    "filter_price.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "c2f41a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on color filter\n",
    "filter_color=driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label/div\")\n",
    "filter_color.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "674ef080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Short-description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Running Shoes</td>\n",
       "      <td>Rs. 7149Rs. 12999(45% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Magnify Nitro Running</td>\n",
       "      <td>Rs. 8449Rs. 12999(35% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Electrify Nitro Running</td>\n",
       "      <td>Rs. 7499Rs. 9999(25% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Men Mid-Top Chelsea Boots</td>\n",
       "      <td>Rs. 9810Rs. 10900(10% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Women Magnify Nitro Shoes</td>\n",
       "      <td>Rs. 7799Rs. 12999(40% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Pavers England</td>\n",
       "      <td>Leather Block Heeled Boots with Bows</td>\n",
       "      <td>Rs. 10999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Calvin Klein</td>\n",
       "      <td>Suede Party High-Top Block Heeled Boots</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Suede High-Top Flatform Heeled Boots</td>\n",
       "      <td>Rs. 8399Rs. 11999(30% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Leather Platform Heeled Boots</td>\n",
       "      <td>Rs. 12599Rs. 17999(30% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Women Chunky Sneakers</td>\n",
       "      <td>Rs. 8910Rs. 9900(Rs. 990 OFF)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                        Short-description  \\\n",
       "0             Puma                        Men Running Shoes   \n",
       "1             Puma                Men Magnify Nitro Running   \n",
       "2             Puma              Men Electrify Nitro Running   \n",
       "3          Saint G                Men Mid-Top Chelsea Boots   \n",
       "4             Puma                Women Magnify Nitro Shoes   \n",
       "..             ...                                      ...   \n",
       "95  Pavers England     Leather Block Heeled Boots with Bows   \n",
       "96    Calvin Klein  Suede Party High-Top Block Heeled Boots   \n",
       "97            Geox     Suede High-Top Flatform Heeled Boots   \n",
       "98            Geox            Leather Platform Heeled Boots   \n",
       "99         Saint G                    Women Chunky Sneakers   \n",
       "\n",
       "                            Price  \n",
       "0      Rs. 7149Rs. 12999(45% OFF)  \n",
       "1      Rs. 8449Rs. 12999(35% OFF)  \n",
       "2       Rs. 7499Rs. 9999(25% OFF)  \n",
       "3      Rs. 9810Rs. 10900(10% OFF)  \n",
       "4      Rs. 7799Rs. 12999(40% OFF)  \n",
       "..                            ...  \n",
       "95                      Rs. 10999  \n",
       "96                       Rs. 9999  \n",
       "97     Rs. 8399Rs. 11999(30% OFF)  \n",
       "98    Rs. 12599Rs. 17999(30% OFF)  \n",
       "99  Rs. 8910Rs. 9900(Rs. 990 OFF)  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating empty lists\n",
    "shoe_names=[]\n",
    "s_desc=[]\n",
    "short_desc=[]\n",
    "price=[]\n",
    "page_urls = []\n",
    "\n",
    "\n",
    "# scrape next pages urls\n",
    "nxt_page = driver.find_elements_by_xpath(\"//ul[@class='pagination-container']/li/a\")\n",
    "for i in nxt_page:\n",
    "    page_urls.append(i.get_attribute('href'))\n",
    "    \n",
    "\n",
    "for url in page_urls[:3]:\n",
    "    driver.get(url)\n",
    "    Names=driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/h3\")  #for scrapping shoe brand names\n",
    "    for i in Names:\n",
    "        shoe_names.append(i.text)\n",
    "    \n",
    "    desc=driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/h4\") #for scrapping shoe short-description\n",
    "    for i in desc:\n",
    "        s_desc.append(i.text)\n",
    "    #As, the s_desc list contain blank description in every alternate index, so removing the blank or null description\n",
    "    for j in range(0,len(s_desc),2):\n",
    "        short_desc.append(s_desc[j])\n",
    "    \n",
    "    rs=driver.find_elements_by_xpath(\"//div[@class='product-price']\")  #for scrapping shoe prices\n",
    "    for i in rs:\n",
    "        price.append(i.text)   \n",
    "df=pd.DataFrame({'Brand': shoe_names[:100],'Short-description': short_desc[:100],'Price': price[:100]})\n",
    "df     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c3cd99",
   "metadata": {},
   "source": [
    "<b>Q9)Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida\n",
    "location. You have to scrape company name, No. of days ago when job was posted, Rating of the company.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the Job option as shown in the image\n",
    "3. After reaching to the next webpage, In place of “Search by Designations, Companies, Skills” enter\n",
    "“Data Scientist” and click on search button.\n",
    "4. You will reach to the following web page click on location and in place of “Search location” enter\n",
    "“Noida” and select location “Noida”.\n",
    "5. Then scrape the data for the first 10 jobs results you get on the above shown page.\n",
    "6. Finally create a dataframe of the scraped data</b>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dec980c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to the webdriver\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "url=(\"https://www.ambitionbox.com/\")\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4fc4c536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"741dbc8789f9fc2ebae77515009b7553\", element=\"51749e2b-7e88-4bdd-bb0c-071172e60390\")>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.sleep(5)\n",
    "#clicking on job heading \n",
    "jobs=driver.find_element_by_xpath(\"//a[@class='link jobs']\")\n",
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "37bba209",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5)\n",
    "jobs.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "de4846b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_box=driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[1]/div/div/div/div/span/input\")\n",
    "search_box.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "37ea9d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"741dbc8789f9fc2ebae77515009b7553\", element=\"7d222230-e3b5-4d43-8af2-3100e2530e30\")>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_btn=driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[1]/div/div/div/button/span\")\n",
    "search_btn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "36165819",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7cae8780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"741dbc8789f9fc2ebae77515009b7553\", element=\"81465527-50c2-4e92-94e2-197865a71a24\")>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clicking filters by selecting check boxes \n",
    "locn=driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[2]/div[1]/div/div/div/div[2]/div[1]/p\")\n",
    "locn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e571cb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)\n",
    "locn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0855371e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching and filtering the location\n",
    "search_locn=driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[2]/input\")\n",
    "search_locn.send_keys(\"Noida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "445b1036",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_locn=driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[3]/div[1]/div[1]/div/label\")\n",
    "filter_locn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1bfb1804",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "time.sleep(5)\n",
    "#scraping company_name\n",
    "company_name=[]\n",
    "company_tag=driver.find_elements_by_xpath('//p[@class=\"company body-medium\"]')\n",
    "for i in company_tag:\n",
    "    company_name.append(i.text)\n",
    "\n",
    "time.sleep(5)\n",
    "#scraping days_ago \n",
    "days_ago=[]\n",
    "days=driver.find_elements_by_xpath('//span[@class=\"body-small-l\"][1]')\n",
    "for i in days:\n",
    "    days_ago.append(i.text)\n",
    "    \n",
    "time.sleep(5)\n",
    "#scraping ratings\n",
    "ratings=[]\n",
    "rating=driver.find_elements_by_xpath('//span[@class=\"body-small\"]')\n",
    "for i in rating:\n",
    "    ratings.append(i.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1f1b63fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>days_ago</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HCL</td>\n",
       "      <td>2d ago</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jubilant Foodworks Limited</td>\n",
       "      <td>2d ago</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ameriprise Financial</td>\n",
       "      <td>4d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Paytm</td>\n",
       "      <td>10d ago</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHT Sapiense</td>\n",
       "      <td>11d ago</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CHT Sapiense</td>\n",
       "      <td>12d ago</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GI Group</td>\n",
       "      <td>23d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GI Group</td>\n",
       "      <td>23d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GI Group</td>\n",
       "      <td>23d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cargoflash</td>\n",
       "      <td>1d ago</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 company_name days_ago ratings\n",
       "0                         HCL   2d ago     3.8\n",
       "1  Jubilant Foodworks Limited   2d ago     3.9\n",
       "2        Ameriprise Financial   4d ago     4.0\n",
       "3                       Paytm  10d ago     3.7\n",
       "4                CHT Sapiense  11d ago     3.8\n",
       "5                CHT Sapiense  12d ago     3.8\n",
       "6                    GI Group  23d ago     4.1\n",
       "7                    GI Group  23d ago     4.1\n",
       "8                    GI Group  23d ago     4.1\n",
       "9                  Cargoflash   1d ago     3.8"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating the DataFrame\n",
    "df=pd.DataFrame({})\n",
    "df['company_name']=company_name[:10]\n",
    "df['days_ago']=days_ago[:10]\n",
    "df['ratings']=ratings[:10]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c56e34d",
   "metadata": {},
   "source": [
    "<b>Q10)Write a python program to scrape the salary data for Data Scientist designation.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Minsalary, Max Salary.\n",
    "The above task will be, done as shown in the below steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the salaries option as shown in the image.\n",
    "3. After reaching to the following webpage, In place of “Search Job Profile” enters “Data Scientist” and\n",
    "then click on “Data Scientist”.\n",
    "You have to scrape the data ticked in the above image.\n",
    "4. Scrape the data for the first 10 companies. Scrape the company name, total salary record, average\n",
    "salary, minimum salary, maximum salary, experience required.\n",
    "5. Store the data in a dataframe.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3813bd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to thr webdriver\n",
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "url=('https://www.ambitionbox.com/')\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b6873135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"6354eb3fa61f196d9b2582d6bad542a1\", element=\"ff00e463-f4ba-44c2-a80c-3c208adbbd88\")>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clicking on salaries\n",
    "salary=driver.find_element_by_xpath(\"/html/body/div[1]/nav/nav/a[4]\")\n",
    "salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c789926f",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(4)\n",
    "salary.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bc621b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"6354eb3fa61f196d9b2582d6bad542a1\", element=\"8a11adff-a8e9-4a4f-b7f7-aff7d84571b5\")>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_box=driver.find_element_by_xpath('/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/input')\n",
    "search_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3b76e8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_box.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "814bc73f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"6354eb3fa61f196d9b2582d6bad542a1\", element=\"591fd058-a393-4f1b-a079-e4b7c5b30588\")>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_box1=driver.find_element_by_xpath('/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/div/div/div[1]/div/div/p')\n",
    "search_box1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2ab0a68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_box1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c42f3416",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping company_name\n",
    "company_name=[]\n",
    "company_tag=driver.find_elements_by_xpath('//div[@class=\"name\"]/a')\n",
    "for i in company_tag:\n",
    "    company_name.append(i.text)\n",
    "#scraping no_of_salaries\n",
    "no_of_salaries=[]\n",
    "salary=driver.find_elements_by_xpath('//div[@class=\"name\"]/span')\n",
    "for i in salary:\n",
    "    no_of_salaries.append(i.text)\n",
    "#scraping min_salaries    \n",
    "min_salaries=[]\n",
    "min_salary=driver.find_elements_by_xpath('//div[@class=\"value body-medium\"]')\n",
    "for i in min_salary:\n",
    "    min_salaries.append(i.text) \n",
    "#scraping average_salaries    \n",
    "average_salaries=[]\n",
    "average_salary=driver.find_elements_by_xpath('//p[@class=\"averageCtc\"]')\n",
    "for i in average_salary:\n",
    "    average_salaries.append(i.text)\n",
    "#scraping max_salaries     \n",
    "max_salaries=[]\n",
    "max_salary=driver.find_elements_by_xpath('//div[@class=\"value body-medium\"]')\n",
    "for i in max_salary:\n",
    "    max_salaries.append(i.text)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7893c0de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>no_of_salries</th>\n",
       "      <th>min_salary</th>\n",
       "      <th>average_salary</th>\n",
       "      <th>max_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>based on 10 salaries</td>\n",
       "      <td>₹ 17.7L</td>\n",
       "      <td>₹ 28.7L</td>\n",
       "      <td>₹ 7.2L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ab Inbev</td>\n",
       "      <td>based on 22 salaries</td>\n",
       "      <td>₹ 35.0L</td>\n",
       "      <td>₹ 19.5L</td>\n",
       "      <td>₹ 20.5L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZS</td>\n",
       "      <td>based on 14 salaries</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 15.8L</td>\n",
       "      <td>₹ 8.3L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>based on 72 salaries</td>\n",
       "      <td>₹ 25.0L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 18.5L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Optum</td>\n",
       "      <td>based on 23 salaries</td>\n",
       "      <td>₹ 9.8L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 10.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnitedHealth</td>\n",
       "      <td>based on 49 salaries</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "      <td>₹ 13.5L</td>\n",
       "      <td>₹ 21.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tiger Analytics</td>\n",
       "      <td>based on 27 salaries</td>\n",
       "      <td>₹ 9.5L</td>\n",
       "      <td>₹ 13.5L</td>\n",
       "      <td>₹ 8.5L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Verizon</td>\n",
       "      <td>based on 14 salaries</td>\n",
       "      <td>₹ 22.0L</td>\n",
       "      <td>₹ 12.7L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ganit Business Solutions</td>\n",
       "      <td>based on 13 salaries</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 12.4L</td>\n",
       "      <td>₹ 5.8L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ericsson</td>\n",
       "      <td>based on 42 salaries</td>\n",
       "      <td>₹ 21.3L</td>\n",
       "      <td>₹ 11.9L</td>\n",
       "      <td>₹ 21.5L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               company_name         no_of_salries min_salary average_salary  \\\n",
       "0                   Walmart  based on 10 salaries    ₹ 17.7L        ₹ 28.7L   \n",
       "1                  Ab Inbev  based on 22 salaries    ₹ 35.0L        ₹ 19.5L   \n",
       "2                        ZS  based on 14 salaries    ₹ 15.0L        ₹ 15.8L   \n",
       "3         Fractal Analytics  based on 72 salaries    ₹ 25.0L        ₹ 15.0L   \n",
       "4                     Optum  based on 23 salaries     ₹ 9.8L        ₹ 15.0L   \n",
       "5              UnitedHealth  based on 49 salaries    ₹ 20.0L        ₹ 13.5L   \n",
       "6           Tiger Analytics  based on 27 salaries     ₹ 9.5L        ₹ 13.5L   \n",
       "7                   Verizon  based on 14 salaries    ₹ 22.0L        ₹ 12.7L   \n",
       "8  Ganit Business Solutions  based on 13 salaries    ₹ 11.0L        ₹ 12.4L   \n",
       "9                  Ericsson  based on 42 salaries    ₹ 21.3L        ₹ 11.9L   \n",
       "\n",
       "  max_salary  \n",
       "0     ₹ 7.2L  \n",
       "1    ₹ 20.5L  \n",
       "2     ₹ 8.3L  \n",
       "3    ₹ 18.5L  \n",
       "4    ₹ 10.0L  \n",
       "5    ₹ 21.0L  \n",
       "6     ₹ 8.5L  \n",
       "7    ₹ 15.0L  \n",
       "8     ₹ 5.8L  \n",
       "9    ₹ 21.5L  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating the DataFrame\n",
    "df=pd.DataFrame({})\n",
    "df['company_name']=company_name[:10]\n",
    "df['no_of_salries']=no_of_salaries[:10]\n",
    "df['min_salary']=min_salaries[:10]\n",
    "df['average_salary']=average_salaries[:10]\n",
    "df['max_salary']=max_salaries[10:20]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f9616a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
